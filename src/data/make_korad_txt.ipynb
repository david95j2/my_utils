{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# make korad txt file (coco format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "import numpy as np\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VOC box (xmin,ymin,xmax,ymax) to COCO box (xmin,ymin, box-width(xmax-xmin), box-height(ymax-ymin))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(size, box):\n",
    "    dw = 1./(size[0])\n",
    "    dh = 1./(size[1])\n",
    "    x = (box[0] + box[1])/2.0 - 1\n",
    "    y = (box[2] + box[3])/2.0 - 1\n",
    "    w = box[1] - box[0]\n",
    "    h = box[3] - box[2]\n",
    "    x = '{:.6f}'.format(round(x*dw,6))\n",
    "    w = '{:.6f}'.format(round(w*dw,6))\n",
    "    y = '{:.6f}'.format(round(y*dh,6))\n",
    "    h = '{:.6f}'.format(round(h*dh,6))\n",
    "    return x,y,w,h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### path random 으로 섞기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(2)\n",
    "\n",
    "root_path = os.path.expanduser(\"~/Desktop/joo/data/korad/data/custom/\")\n",
    "label_set = set(map(lambda x : x[-13:-4] if x[-4:]==\".jpg\" else x[-14:-5],glob.glob(root_path+\"images/*/*\")))\n",
    "labels = list(label_set)\n",
    "random.shuffle(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./korad_boxes/all_list.json\", \"r\") as f:\n",
    "    all_dict = json.load(f)\n",
    "    train_ratio = 0.82\n",
    "    val_ratio = 0.15\n",
    "    test_ratio = 0.03\n",
    "\n",
    "    train_set = 0\n",
    "    val_set = 0\n",
    "    test_set = 0\n",
    "    \n",
    "    error_set = 0\n",
    "\n",
    "    for index, data_id in enumerate(all_dict.keys()):\n",
    "        # if index == 10 : break\n",
    "            \n",
    "        rd_num = np.random.random()\n",
    "        \n",
    "        _, _, json_true = all_dict[data_id]\n",
    "        \n",
    "        if json_true == None :rd_num = 1\n",
    "        \n",
    "        if rd_num < train_ratio :\n",
    "            train_set += 1\n",
    "            datatype = [\"train\"]\n",
    "\n",
    "        elif rd_num < train_ratio + val_ratio:\n",
    "            val_set += 1\n",
    "            datatype = [\"val\"]\n",
    "        else :\n",
    "            if rd_num == 1 : error_set += 1\n",
    "            test_set += 1\n",
    "            datatype = [\"test\"]\n",
    "        all_dict[data_id] = all_dict[data_id] + datatype\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_set : 18421개 (0.79%)\n",
      "val_set : 3419개 (0.15%)\n",
      "test_set : 646 + 914(error file) = 1560개 (0.07%)\n"
     ]
    }
   ],
   "source": [
    "print(f\"train_set : {train_set}개 ({train_set/23400:.2f}%)\")\n",
    "print(f\"val_set : {val_set}개 ({val_set/23400:.2f}%)\")\n",
    "print(f\"test_set : {test_set - error_set} + {error_set}(error file) = {test_set}개 ({test_set/23400:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\"ConcreteCrack\", \"AlligatorCrack\",\"Spalling\", \"Efflorescene\", \"Exposure\"]\n",
    "year = \"2022\"\n",
    "save_path = [\"train\",\"val\",\"test\"]\n",
    "\n",
    "# txt 초기화\n",
    "for write_type in save_path:\n",
    "    with open(root_path+write_type+year+\".txt\", \"w\") as file: file.writelines(\"\")\n",
    "\n",
    "# txt in labels\n",
    "for index, file in enumerate(labels):\n",
    "    \n",
    "    number, img_file, json_file_name, data_type = all_dict[file]\n",
    "\n",
    "    with open(root_path+data_type+year+\".txt\", \"a\") as file: \n",
    "            file.writelines(\"./images/\"+number+\"/\"+img_file+\"\\n\")\n",
    "\n",
    "    if json_file_name == None: continue\n",
    "    \n",
    "    with open(root_path+\"labeling/\"+number+\"/\"+json_file_name, \"r\") as f: json_file = json.load(f)\n",
    "\n",
    "    width = json_file['images']['width']\n",
    "    height = json_file['images']['height']\n",
    "    save_true = True\n",
    "\n",
    "    for label in json_file['labels']:\n",
    "        class_num = str(classes.index(label['label']))\n",
    "        xmin = label['boundingPoly']['vertices'][0]['xmin']\n",
    "        ymin = label['boundingPoly']['vertices'][0]['ymin']\n",
    "        xmax = label['boundingPoly']['vertices'][0]['xmax']\n",
    "        ymax = label['boundingPoly']['vertices'][0]['ymax']\n",
    "\n",
    "        bb = convert((width,height),(xmin,xmax,ymin,ymax))\n",
    "        \n",
    "        if save_true:\n",
    "            with open(root_path+\"labels/\"+data_type+year+\"/\"+json_file_name[:-5]+\".txt\", \"w\") as file:\n",
    "                file.writelines(class_num + \" \"+bb[0]+\" \"+bb[1]+\" \"+bb[2]+\" \"+bb[3]+\" \\n\")\n",
    "            save_true = False\n",
    "        else:\n",
    "            with open(root_path+\"labels/\"+data_type+year+\"/\"+json_file_name[:-5]+\".txt\", \"a\") as file:\n",
    "                file.writelines(class_num + \" \"+bb[0]+\" \"+bb[1]+\" \"+bb[2]+\" \"+bb[3]+\" \\n\")\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18412 3461 617 910 1527 23400\n",
      "23400\n",
      "22486\n",
      "910\n",
      "{'C03_02787', 'C05_03486', 'C03_01098', 'C03_00711'}\n"
     ]
    }
   ],
   "source": [
    "a,b,c_1,c_2 = 0,0,0,0\n",
    "for id in all_dict:\n",
    "    _,_,json_ty,ty = all_dict[id]\n",
    "    if ty == \"train\": a += 1\n",
    "    elif ty == \"val\": b += 1\n",
    "    elif ty == \"test\" : \n",
    "        if json_ty != None:\n",
    "            c_1 += 1\n",
    "            continue\n",
    "        c_2 += 1\n",
    "\n",
    "print(a,b,c_1,c_2, c_1+c_2, a+b+c_1+c_2)\n",
    "\n",
    "temp_set = set(map(lambda x : x[-13:-4] , glob.glob(root_path+\"labels/*/*\")))\n",
    "print(len(label_set))\n",
    "print(len(temp_set))\n",
    "\n",
    "temp_err = label_set - temp_set\n",
    "temp_dict = set()\n",
    "\n",
    "with open(os.path.expanduser(\"./korad_boxes/error_list.json\"), \"r\") as f: \n",
    "    json_file = json.load(f)\n",
    "    for i in json_file.keys(): \n",
    "        temp_dict.add(i)\n",
    "\n",
    "with open(os.path.expanduser(\"./korad_boxes/error_list2.json\"), \"r\") as f: \n",
    "    json_file = json.load(f)\n",
    "    for i in json_file.keys(): \n",
    "        temp_dict.add(i)        \n",
    "print(len(temp_dict))\n",
    "\n",
    "print(temp_err - temp_dict)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3a1e0c3fd6bfde654019c6597bc01b0340aa41dd1aa19c1037b8b7c3290c1f6b"
  },
  "kernelspec": {
   "display_name": "Python 3.6.9 ('utils': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
