{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from torchinfo import summary\n",
    "from torchviz import make_dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, self.expansion*planes, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = F.relu(self.bn2(self.conv2(out)))\n",
    "        out = self.bn3(self.conv3(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class FPN(nn.Module):\n",
    "    def __init__(self, block, num_blocks):\n",
    "        super().__init__()\n",
    "        self.in_planes = 64\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "\n",
    "        # Bottom-up layers\n",
    "        self.layer1 = self._make_layer(block,  64, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
    "\n",
    "        # Top layer\n",
    "        self.toplayer = nn.Conv2d(2048, 256, kernel_size=1, stride=1, padding=0)  # Reduce channels\n",
    "\n",
    "        # Smooth layers\n",
    "        self.smooth1 = nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1)\n",
    "        self.smooth2 = nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1)\n",
    "        self.smooth3 = nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        # Lateral layers\n",
    "        self.latlayer1 = nn.Conv2d(1024, 256, kernel_size=1, stride=1, padding=0)\n",
    "        self.latlayer2 = nn.Conv2d( 512, 256, kernel_size=1, stride=1, padding=0)\n",
    "        self.latlayer3 = nn.Conv2d( 256, 256, kernel_size=1, stride=1, padding=0)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def _upsample_add(self, x, y):\n",
    "        '''Upsample and add two feature maps.\n",
    "        Args:\n",
    "          x: (Variable) top feature map to be upsampled.\n",
    "          y: (Variable) lateral feature map.\n",
    "        Returns:\n",
    "          (Variable) added feature map.\n",
    "        Note in PyTorch, when input size is odd, the upsampled feature map\n",
    "        with `F.upsample(..., scale_factor=2, mode='nearest')`\n",
    "        maybe not equal to the lateral feature map size.\n",
    "        e.g.\n",
    "        original input size: [N,_,15,15] ->\n",
    "        conv2d feature map size: [N,_,8,8] ->\n",
    "        upsampled feature map size: [N,_,16,16]\n",
    "        So we choose bilinear upsample which supports arbitrary output sizes.\n",
    "        '''\n",
    "        _,_,H,W = y.size()\n",
    "        return F.upsample(x, size=(H,W), mode='bilinear') + y\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Bottom-up\n",
    "        c1 = F.relu(self.bn1(self.conv1(x)))\n",
    "        c1 = F.max_pool2d(c1, kernel_size=3, stride=2, padding=1)\n",
    "        c2 = self.layer1(c1)\n",
    "        c3 = self.layer2(c2)\n",
    "        c4 = self.layer3(c3)\n",
    "        c5 = self.layer4(c4)\n",
    "        # Top-down\n",
    "        p5 = self.toplayer(c5)\n",
    "        p4 = self._upsample_add(p5, self.latlayer1(c4))\n",
    "        p3 = self._upsample_add(p4, self.latlayer2(c3))\n",
    "        p2 = self._upsample_add(p3, self.latlayer3(c2))\n",
    "        # Smooth\n",
    "        p4 = self.smooth1(p4)\n",
    "        p3 = self.smooth2(p3)\n",
    "        p2 = self.smooth3(p2)\n",
    "        return p2, p3, p4, p5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joo/vsc/workspaces/my_utils/my_utils/lib/python3.6/site-packages/torch/nn/functional.py:3509: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
      "/home/joo/vsc/workspaces/my_utils/my_utils/lib/python3.6/site-packages/torch/nn/functional.py:3635: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  \"See the documentation of nn.Upsample for details.\".format(mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "FPN                                      --                        --\n",
      "├─Conv2d: 1-1                            [1, 64, 256, 256]         9,408\n",
      "├─BatchNorm2d: 1-2                       [1, 64, 256, 256]         128\n",
      "├─Sequential: 1-3                        [1, 256, 128, 128]        --\n",
      "│    └─Bottleneck: 2-1                   [1, 256, 128, 128]        --\n",
      "│    │    └─Conv2d: 3-1                  [1, 64, 128, 128]         4,096\n",
      "│    │    └─BatchNorm2d: 3-2             [1, 64, 128, 128]         128\n",
      "│    │    └─Conv2d: 3-3                  [1, 64, 128, 128]         36,864\n",
      "│    │    └─BatchNorm2d: 3-4             [1, 64, 128, 128]         128\n",
      "│    │    └─Conv2d: 3-5                  [1, 256, 128, 128]        16,384\n",
      "│    │    └─BatchNorm2d: 3-6             [1, 256, 128, 128]        512\n",
      "│    │    └─Sequential: 3-7              [1, 256, 128, 128]        16,896\n",
      "│    └─Bottleneck: 2-2                   [1, 256, 128, 128]        --\n",
      "│    │    └─Conv2d: 3-8                  [1, 64, 128, 128]         16,384\n",
      "│    │    └─BatchNorm2d: 3-9             [1, 64, 128, 128]         128\n",
      "│    │    └─Conv2d: 3-10                 [1, 64, 128, 128]         36,864\n",
      "│    │    └─BatchNorm2d: 3-11            [1, 64, 128, 128]         128\n",
      "│    │    └─Conv2d: 3-12                 [1, 256, 128, 128]        16,384\n",
      "│    │    └─BatchNorm2d: 3-13            [1, 256, 128, 128]        512\n",
      "│    │    └─Sequential: 3-14             [1, 256, 128, 128]        --\n",
      "├─Sequential: 1-4                        [1, 512, 64, 64]          --\n",
      "│    └─Bottleneck: 2-3                   [1, 512, 64, 64]          --\n",
      "│    │    └─Conv2d: 3-15                 [1, 128, 128, 128]        32,768\n",
      "│    │    └─BatchNorm2d: 3-16            [1, 128, 128, 128]        256\n",
      "│    │    └─Conv2d: 3-17                 [1, 128, 64, 64]          147,456\n",
      "│    │    └─BatchNorm2d: 3-18            [1, 128, 64, 64]          256\n",
      "│    │    └─Conv2d: 3-19                 [1, 512, 64, 64]          65,536\n",
      "│    │    └─BatchNorm2d: 3-20            [1, 512, 64, 64]          1,024\n",
      "│    │    └─Sequential: 3-21             [1, 512, 64, 64]          132,096\n",
      "│    └─Bottleneck: 2-4                   [1, 512, 64, 64]          --\n",
      "│    │    └─Conv2d: 3-22                 [1, 128, 64, 64]          65,536\n",
      "│    │    └─BatchNorm2d: 3-23            [1, 128, 64, 64]          256\n",
      "│    │    └─Conv2d: 3-24                 [1, 128, 64, 64]          147,456\n",
      "│    │    └─BatchNorm2d: 3-25            [1, 128, 64, 64]          256\n",
      "│    │    └─Conv2d: 3-26                 [1, 512, 64, 64]          65,536\n",
      "│    │    └─BatchNorm2d: 3-27            [1, 512, 64, 64]          1,024\n",
      "│    │    └─Sequential: 3-28             [1, 512, 64, 64]          --\n",
      "├─Sequential: 1-5                        [1, 1024, 32, 32]         --\n",
      "│    └─Bottleneck: 2-5                   [1, 1024, 32, 32]         --\n",
      "│    │    └─Conv2d: 3-29                 [1, 256, 64, 64]          131,072\n",
      "│    │    └─BatchNorm2d: 3-30            [1, 256, 64, 64]          512\n",
      "│    │    └─Conv2d: 3-31                 [1, 256, 32, 32]          589,824\n",
      "│    │    └─BatchNorm2d: 3-32            [1, 256, 32, 32]          512\n",
      "│    │    └─Conv2d: 3-33                 [1, 1024, 32, 32]         262,144\n",
      "│    │    └─BatchNorm2d: 3-34            [1, 1024, 32, 32]         2,048\n",
      "│    │    └─Sequential: 3-35             [1, 1024, 32, 32]         526,336\n",
      "│    └─Bottleneck: 2-6                   [1, 1024, 32, 32]         --\n",
      "│    │    └─Conv2d: 3-36                 [1, 256, 32, 32]          262,144\n",
      "│    │    └─BatchNorm2d: 3-37            [1, 256, 32, 32]          512\n",
      "│    │    └─Conv2d: 3-38                 [1, 256, 32, 32]          589,824\n",
      "│    │    └─BatchNorm2d: 3-39            [1, 256, 32, 32]          512\n",
      "│    │    └─Conv2d: 3-40                 [1, 1024, 32, 32]         262,144\n",
      "│    │    └─BatchNorm2d: 3-41            [1, 1024, 32, 32]         2,048\n",
      "│    │    └─Sequential: 3-42             [1, 1024, 32, 32]         --\n",
      "├─Sequential: 1-6                        [1, 2048, 16, 16]         --\n",
      "│    └─Bottleneck: 2-7                   [1, 2048, 16, 16]         --\n",
      "│    │    └─Conv2d: 3-43                 [1, 512, 32, 32]          524,288\n",
      "│    │    └─BatchNorm2d: 3-44            [1, 512, 32, 32]          1,024\n",
      "│    │    └─Conv2d: 3-45                 [1, 512, 16, 16]          2,359,296\n",
      "│    │    └─BatchNorm2d: 3-46            [1, 512, 16, 16]          1,024\n",
      "│    │    └─Conv2d: 3-47                 [1, 2048, 16, 16]         1,048,576\n",
      "│    │    └─BatchNorm2d: 3-48            [1, 2048, 16, 16]         4,096\n",
      "│    │    └─Sequential: 3-49             [1, 2048, 16, 16]         2,101,248\n",
      "│    └─Bottleneck: 2-8                   [1, 2048, 16, 16]         --\n",
      "│    │    └─Conv2d: 3-50                 [1, 512, 16, 16]          1,048,576\n",
      "│    │    └─BatchNorm2d: 3-51            [1, 512, 16, 16]          1,024\n",
      "│    │    └─Conv2d: 3-52                 [1, 512, 16, 16]          2,359,296\n",
      "│    │    └─BatchNorm2d: 3-53            [1, 512, 16, 16]          1,024\n",
      "│    │    └─Conv2d: 3-54                 [1, 2048, 16, 16]         1,048,576\n",
      "│    │    └─BatchNorm2d: 3-55            [1, 2048, 16, 16]         4,096\n",
      "│    │    └─Sequential: 3-56             [1, 2048, 16, 16]         --\n",
      "├─Conv2d: 1-7                            [1, 256, 16, 16]          524,544\n",
      "├─Conv2d: 1-8                            [1, 256, 32, 32]          262,400\n",
      "├─Conv2d: 1-9                            [1, 256, 64, 64]          131,328\n",
      "├─Conv2d: 1-10                           [1, 256, 128, 128]        65,792\n",
      "├─Conv2d: 1-11                           [1, 256, 32, 32]          590,080\n",
      "├─Conv2d: 1-12                           [1, 256, 64, 64]          590,080\n",
      "├─Conv2d: 1-13                           [1, 256, 128, 128]        590,080\n",
      "==========================================================================================\n",
      "Total params: 16,700,480\n",
      "Trainable params: 16,700,480\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (G): 26.93\n",
      "==========================================================================================\n",
      "Input size (MB): 3.15\n",
      "Forward/backward pass size (MB): 703.07\n",
      "Params size (MB): 66.80\n",
      "Estimated Total Size (MB): 773.02\n",
      "==========================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joo/vsc/workspaces/my_utils/my_utils/lib/python3.6/site-packages/torch/onnx/symbolic_helper.py:382: UserWarning: You are trying to export the model with onnx:Upsample for ONNX opset version 9. This operator might cause results to not match the expected results by PyTorch.\n",
      "ONNX's Upsample/Resize operator did not match Pytorch's Interpolation until opset 11. Attributes to determine how to transform the input were added in onnx:Resize in opset 11 to support Pytorch's behavior (like coordinate_transformation_mode and nearest_mode).\n",
      "We recommend using opset 11 and above for models using this operator.\n",
      "  \"\" + str(_export_onnx_opset_version) + \". \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 256, 128, 128])\n",
      "torch.Size([1, 256, 64, 64])\n",
      "torch.Size([1, 256, 32, 32])\n",
      "torch.Size([1, 256, 16, 16])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def FPN101():\n",
    "    # return FPN(Bottleneck, [2,4,23,3])\n",
    "    return FPN(Bottleneck, [2,2,2,2])\n",
    "\n",
    "\n",
    "def test():\n",
    "    net = FPN101().cuda()\n",
    "    print(summary(net,(1,3,512,512)))\n",
    "    \n",
    "    # 2. model의 파라미터를 OrderedDict 형태로 저장합니다.\n",
    "    params = net.state_dict()\n",
    "\n",
    "    # 3. 동적 그래프 형태의 pytorch model을 위하여 data를 model로 흘려주기 위한 더미 데이터 입니다.\n",
    "    dummy_data = torch.empty(1, 3, 512, 512, dtype = torch.float32)\n",
    "\n",
    "    # 4. onnx 파일을 export 해줍니다. 함수에는 차례대로 model, data, 저장할 파일명 순서대로 들어가면 됩니다.\n",
    "    torch.onnx.export(net.cpu(), dummy_data, \"output.onnx\")\n",
    "\n",
    "    net.cpu()\n",
    "    fms = net(Variable(torch.randn(1,3,512,512)))\n",
    "    for fm in fms:\n",
    "        print(fm.size())\n",
    "    \n",
    "\n",
    "\n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "931c51123006e60165af15061917cfb5158bca79165496975f65700b2eb01b27"
  },
  "kernelspec": {
   "display_name": "Python 3.6.9 ('my_utils': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
